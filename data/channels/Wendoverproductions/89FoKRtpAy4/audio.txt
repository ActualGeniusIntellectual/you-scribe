The end might not be near.
Doom might not be inevitable.
But not according to the news.
After a weekend of dramatic White House emergency actions, US President-
Biden has given the go-ahead for a controversial oil drilling scheme, environmentalists say
it's a carbon bomb.
And despite a wet winter in the West, persistent drought and overdevelopment cause record low
water levels for tens of millions of Americans.
Imagine a forest.
Imagine it's your home.
It's both your shelter and your source of sustenance.
It offers rocks to make axes, timber to build shelters, but most importantly, berries and
nuts and ducks and all sorts of food, but to get to it, you have to go out.
Out is scary.
Out is where the threats are.
You're on a path.
Your sightlines are limited.
This forces you to walk.
To search.
As a necessity for survival, to find the food that will feed you, your mate, or your child
that will ensure a slightly altered copy of your DNA gets copied once again, to keep
the species alive, you need to tread into the unknown.
So you walk, and you search, and you walk, and you search, and you walk, and you search,
and you walk, and you- bear, there's a bear!
Epinephrine, cortisol, your heart rate spikes, breathing quickens, blood vessels contract,
digestion stops, your vision focuses, your pupils dilate, your hearing drops out, your
muscles tense, and within an instant, your body has reworked itself—reprioritize resources,
switching from a physiological state suited to exploring to one that can best assess,
address, or evade a threat.
This split-second moment of identifying a threat has occurred immeasurable times through
human history, ending in immeasurable different outcomes, but each of these outcomes can be
categorized into one of two categories—survival or death.
Various factors altered each—a slippery rock slowed to retreat, a convenient cave
offered refuge, a blunt spear inhibited a defense—but when summing up the total of
those immeasurable instances, there was a pattern.
The degree of that physiological response correlated to the likelihood of survival.
How well muscles tense, how much vision focused, how quickly cortisol released—all this mattered
to whether or not a human survived an encounter with a threat, so, through the totality of
humanity, the DNA that created humans with a stronger response to the negative was more
likely to get recreated through offspring.
That's evolution.
But that's also a theory.
What we do know with certainty is that today's humans respond more strongly to a negative
stimulus than a positive one, even when those two stimuli are objectively equal in weight.
Think back to high school—what do you remember?
The great jokes you told, or all the awkward encounters?
This disproportionate response is something that we can and have proved time and time
again in academic research, so we call it the negativity bias.
But what we can't directly prove is whether or not this is something natural—something
rooted in our DNA, crafted by evolution, or if it's cultural.
Maybe society overemphasizes negative moments.
Maybe the awkward encounters from middle school really did have more of an impact on others'
perception of us than the great jokes, and so we've learned to react to them appropriately.
But evolution leaves its fingerprints, and natural experiments can search for them.
Certain humans are male, certain others are female, and the most critical component of
evolution is reproduction.
During human pregnancy, the evolutionary influence of parental death differs depending on whether
it occurs to a father or mother.
If a father dies, the likelihood of reproductive success does go down.
There's then only one individual in a diminished physical state to find food and fight off
threats, but there's still a chance.
If the mother dies, however, that's it.
Reproduction fails.
Evolution stops.
But simultaneously, in an era when pregnancy was far more perilous than today, reproductive
success went up when food was more plentiful.
Therefore, the chance of a father's DNA getting passed on increased as they found
more food, but to do so, they couldn't be too worried about the negative—the threats.
They needed to be motivated to take the level of risk that optimizes for finding the most
food possible, even if it increases their chances of death.
Meanwhile, the mother, with far higher and more direct evolutionary pressure to survive,
must first and foremost focus on her and her child's survival.
Her fight or flight response needs to be huge so she's able to best respond to any threat
that she might encounter.
When studied, the facts support this theory.
Female humans exhibit a weaker negativity bias than female ones.
They still have the bias—they still respond disproportionately to the negative—but not
quite as strongly.
It seems like evolution worked, crafting a structure that appropriately optimized for
the greatest likelihood of successful reproduction.
So, the case is made.
As best we can tell, the negativity bias was not learned—it was evolved.
It's natural.
The positive just doesn't elicit the same emotional response in humans, and there's
not a whole lot we can do about it because it is literally rooted in our DNA that developed
before farming and restaurants and electricity and supermarkets and telephones and TV and
the internet and the information overload that inundated us far faster than evolution
could possibly respond.
We are dumb monkeys using our dumb monkey brains to trick other dumb monkeys into giving
other dumb monkeys attention, and there's nothing we can do about it.
So, we react more quickly and with more force to the negative.
It follows, then, that our eyes are naturally drawn first towards the day's bad news.
But the trend towards the negative starts even before you, the consumer—it begins
with the journalist.
Subject to the same natural negativity bias, it's more likely that what a journalist
ends up pitching to their editor takes on a negative slant.
Subconsciously, it just feels more important to cover, more exciting to follow, and carries
more potential to captivate an audience.
This negative lean, of course, goes up the line—influencing the editor that then green
lines the story, the news institution that publishes the story, and the award juries
that recognize exceptional work.
Next, the negativity bias gets rewarded by the public.
It supplies a demand—receiving clicks, views, engagement, outrage, and attention from people
who can't help but react to the bad news.
It's all pretty intuitive—bad news proliferates because it's biologically what reporters
are drawn to report on and consumers are drawn to consume.
But none of this explains why some countries' media is more negative than others.
That has less to do with human nature, and more with how a society goes about making
news.
Among journalists, there's surprisingly little consensus as to what exactly is defined
as news.
Sure, there's a dictionary definition, but it's so broad that it might be easier to
identify what news isn't than is.
A functional definition, on the other hand, has proved hard to come by and harder to agree
on.
Among journalists, news is news when it fits into one or more of these particular, identifiable
bins.
For others, the list slightly differs.
For others, still, the notion of even trying to qualify what actually counts as news is
too much to ask.
You know it when you see it—it simply is.
Zoom out further, and questions become more vexing.
What is news for?
Is it entertainment, or a public service?
Whose role is it to produce and provide the news—the state or independent organizations?
Who does the news serve—stakeholders, shareholders, the state, the public?
But while these questions might keep academics up at night, media institutions answer them
every moment of every day with every piece they publish—offering through example after
example of exactly what that particular society has decided to define as news and the purpose
of news.
For decades, critical onlookers have scanned America's pro-private, hyper-competitive,
for-profit media landscape, and have drawn two broad conclusions.
It tends to be more negative than most, and it's getting more negative.
What's been more difficult, though, was proving to what extent, if any, US media skewed
more negatively than other nations.
With different events impacting different countries, after all, and with different cultural
assumptions as to what different events mean, it's nearly impossible drawing a clean comparison
between any two nations' media.
Maybe, in a bigger country, there's just too much bad happening to leave airtime for
the good.
Well, that was until one story came to impact every single media market on the planet at
the exact same time.
Really like no other phenomena before it, the COVID-19 pandemic and its near-universal
weight offered the rarest of opportunities to compare media tone across countries.
Some identified the chance, and in early 2021, this paper, analyzing and comparing English
language stories' approach to reporting on the pandemic, went public.
Collecting some 20,000 COVID articles from these sources in the US and these sources
abroad, the researchers traced the prevalence of negative words and terms to predict the
negative slant of each.
The results were staggering.
This is the negativity trend in international sources across much of 2020, hovering steadily
around 50%.
Then this is the US media, whose COVID-19 coverage leaned negative at a whopping 87%
across the study.
And this vast gulf between just how bad the news is in the US versus the rest of the world
is only exacerbated by these additional findings—that the nation's most popular news sources trend
even more negative than average performers.
Clearly, the negativity bias is working, fueling a vicious cycle that will only lead to more
and more and more of it, and this all feels like a problem.
But maybe it's not.
Maybe it's just a thing.
Overall, this is natural.
Maybe negativity is just how we communicate.
Maybe it's even a good thing—we talk about our issues, meaning we find ways to address
them.
Or maybe it can be both—a simultaneous source and stymie of progress.
Consider it theoretically.
Say negative news gets just 10% more attention.
First, one must consider that it's an arms race.
There are only so many eyeballs, so when the success metric is eyeballs in a competitive
news industry, any edge, be it little, will get captured.
So, a 10% attention edge will lead to 20 or 30 or 40% more negative news, because if everyone
else is doing it, then everybody has to do it—it's an exponential effect.
Next, say there are two stories, but there's only time for one.
The first is on a brand new vaccine—a miracle cure—something that will improve one's
odds of survival by 50%.
The second is on a crime wave—a shooting spree—something that will decrease the odds
of survival by 5%.
In this theoretical environment, that second story wins.
It's scarier, it's more dramatic, it's going to keep the eyeballs from switching
to that other channel.
This will kill people.
The crime wave might stop, the attention might lead to intervention, but all the while, more
people are dying of a preventable disease—an epidemic that could have been stopped if only
people had heard of that new miracle cure.
In our heads, problems feel far more significant than potential—we'd much rather solve
a problem than capture potential.
Early in the COVID pandemic, there was no news but COVID news, but not all was negative.
There were times when things got better—for every upslope, there was a downslope, but you
could hardly tell based on the news.
Research into the matter found that the degree of negativity of COVID news had little, in
fact, sometimes inverse correlation with the COVID case count at the given moment.
This meant that, while a news consumer might have theoretically known that things were
comparatively better or worse, it didn't necessarily feel that way since the tone of
the media inputs stayed consistently dire.
This did have an impact.
Now, with retrospect, we understand the cost of COVID precautions.
Precautions got in the way of precautions.
The persistence of mask mandates and school closures and border restrictions led to a
changing calculus of when these should have been implemented in the public's minds.
Think of it like this—if a town will have only tolerated 12 months of mask mandates
over 36 months of the pandemic, they probably should have been applied here, as hospitalizations
and deaths were rising most quickly, but rather, on average, they were applied here—at the
start—distretching until tolerance waned, meaning a limited supply of precaution was
wasted on times when cases were naturally waning.
Of course this sort of rationality can only be applied in retrospect, but it demonstrates
the impact—we were incapable of properly assessing risk, perhaps in part because our
information inputs didn't modulate tone in step with the risk.
Things always felt at their worst, so it never felt like the moment for a reprieve.
Take another, dramatically different example—research has demonstrated that US presidents, in elections
for a second term, are penalized more for a worsening economy than rewarded for an improving
one.
That's not to say, making the economy 5% worse matters a lot more to the electorate
than making the economy 5% better, possibly because the public hardly knows when things
are getting better—the media doesn't talk about it, only the reverse.
But what the electorate should optimize for is the president who is best at improving
the economy, and so this skew means there's ever so slight irrationality in how we assess
a politician.
We've potentially voted out presidents, and more often other politicians, irrationally
because we don't have an understanding of their accomplishments.
It's a game of who's more terrible rather than who's the best.
So the news operates as perhaps a distorted funhouse mirror of society.
It is mostly accurate, it mostly conveys the truth, but waiting matters.
The public makes inferences based on the quantity and frequency of information, and so this
distorted mirror does inject irrational information into both democratic and individual decision-making.
There are interventions.
We know this because we know this negativity bias is at its worst in the US.
Australia and the UK, for example, are close cultural cousins to the US, and yet their
media tends to be far less negative.
Perhaps the most notable difference in their media landscape is the dominance of public
broadcasters.
The Australian and British broadcasting corporations are incredibly influential in shaping public
opinion in their respective countries, and do so without needing to so fiercely compete
to attract eyeballs.
They can optimize for quality of information over eyeballs attracted, as their funding
is less directly tied to quantity of eyeballs.
They each rely on money from the public, funded through the government, meaning the metric
of success is providing a service the public considers worthwhile.
But inevitably, everyone's definition of worthwhile is different.
True autonomy from the government, while relying on politicians to continue to authorize funding,
is near impossible to achieve, and public broadcasters constantly face scandals for
failing to properly critique those who write their checks.
So, while negativity might be lower, some might ask at what cost.
True media autonomy is essentially impossible under a public funding model.
True tone balance is essentially impossible under an ad-supported model.
There's really no perfect option, and at the end of the day, it's not a question
of if there's negativity bias, just how much.
When we look into a distorted funhouse mirror, we don't think our heads actually look that
big or our stature is actually that short or our hips are actually that wide, because
we know that's not reality.
We've seen ourselves in normal mirrors, so we know what we actually look like.
But if you never saw yourself through a normal mirror, if that funhouse option was it, you
might know that your head and height and hips are not that size, but slowly, you'd forget
by just how much.
You'd forget what you actually look like—blind to yourself, left only with the choice of
avoiding the mirror, rejecting any sort of self-reflection, or accepting a flawed image
because it's really the only mirror you have.
Access to information is undoubtedly important, and there has perhaps never been a more powerful
tool for this than the internet.
But as the power of the internet has increased, there's been a worrying trend towards its
nationalization.
The internet should be the exact same no matter where you are, but it's not.
There are an increasing number of censorship firewalls, legislation limiting where you
can access what, and different versions of sites depending on the country.
I encounter this all the time when researching for videos.
Sometimes I'm trying to watch a British news report on YouTube that's blocked in
the US, or read an American website when traveling in Europe that's blocked due to GDPR legislation.
That's why our sponsor, NordVPN, is a crucial tool for making your internet experience as
free and open as possible.
You're able to route your traffic through servers in any one of 60 countries, so you
might be sitting in Illinois, but as far as your computer's concerned, you're in
London or Tokyo or Sydney.
And this matters for more than just accessing the different versions of the internet.
If you're on public wifi or in certain countries with government surveillance programs, routing
your traffic through a VPN is a crucial way to make sure that you get the privacy and
safety you deserve, and with Nord's new threat protection, it can keep you safe from
phishing links and malware, while also letting you know when any of your information has
been leaked recently.
But you probably already know this—VPNs aren't a new concept, and while they might
be more crucial than ever, there are plenty of options.
The reason I use NordVPN is because they recognize that and have worked to become the best.
They use next-generation encryption to ensure your privacy, they use a dedicated IP to avoid
VPN blockers, and they have super fast speeds so you don't even notice you're using
a VPN, and they just introduced a lightweight browser extension that allows you to customize
which websites you use a VPN for.
I consider VPNs worth it just for the entertainment benefits—being able to unlock the streaming
libraries of other countries—but then there's so much more on top of that, and NordVPN
gives you the best experience possible, so I'd absolutely recommend it, especially
considering the deal they're offering right now.
It's risk-free with Nord's 30-day money-back guarantee, and for a limited time when you
use our link, NordVPN.com slash Wendover, any two-year plan will include four free bonus
months and you'll be helping support the channel while you're at it, so click the
button on screen or the link in the description to sign up.
