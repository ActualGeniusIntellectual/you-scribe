WEBVTT

00:00.000 --> 00:06.420
Imagine a future where your toaster anticipates what kind of toast you want.

00:06.420 --> 00:10.940
During the day, it scans the internet for new and exciting types of toast.

00:10.940 --> 00:16.540
Maybe it asks you about your day and wants to chat about new achievements in toast technology.

00:16.540 --> 00:22.260
At what level would it become a person? At which point will you ask yourself if your

00:22.260 --> 00:28.500
toaster has feelings? If it did, would unplugging it be murder? And would you still own it?

00:29.460 --> 00:32.580
Will we someday be forced to give our machines rights?

00:43.140 --> 00:48.340
AI is already all around you. It makes sure discounters are stocked with enough snacks,

00:48.340 --> 00:52.900
it serves you up just the right internet ad, and you may have even read a news story written

00:52.900 --> 00:59.140
entirely by a machine. Right now, we look at chatbots like Siri and laugh at their primitive

00:59.140 --> 01:04.740
simulated emotions, but it's likely that we will have to deal with beings that make it hard to draw

01:04.740 --> 01:11.380
the line between real and simulated humanity. Are there any machines in existence that deserve

01:11.380 --> 01:19.540
rights? Most likely not yet. But if they come, we are not prepared for it. Much of the philosophy

01:19.540 --> 01:24.980
of rights is ill-equipped to deal with the case of artificial intelligence. Most claims for rights,

01:24.980 --> 01:30.660
whether human or animal, are centered around the question of consciousness. Unfortunately,

01:30.660 --> 01:35.940
nobody knows what consciousness is. Some think that it's immaterial, others say it's a state

01:35.940 --> 01:42.820
of matter like gas or liquid. Regardless of the precise definition, we have an intuitive knowledge

01:42.820 --> 01:48.740
of consciousness because we experience it. We're aware of ourselves and our surroundings and know

01:48.740 --> 01:55.460
what unconsciousness feels like. Some neuroscientists believe that any sufficiently advanced system

01:55.460 --> 02:01.060
can generate consciousness. So if your toaster's hardware was powerful enough, it may become

02:01.060 --> 02:09.620
self-aware. If it does, would it deserve rights? Well, not so fast. Would what we define as rights

02:09.620 --> 02:15.940
make sense to it? Consciousness entitles beings to have rights because it gives a being the ability

02:15.940 --> 02:23.700
to suffer. It means the ability to not only feel pain but to be aware of it. Robots don't suffer

02:23.700 --> 02:30.260
and they probably won't unless we program them to. Without pain or pleasure, there's no preference

02:30.260 --> 02:36.420
and rights are meaningless. Our human rights are deeply tied to our own programming.

02:37.140 --> 02:42.900
For example, we dislike pain because our brains evolved to keep us alive, to stop us from touching

02:42.900 --> 02:49.060
a hot fire or to make us run away from predators. So we came up with rights that protect us from

02:49.060 --> 02:54.660
infringements that cause us pain. Even more abstract rights like freedom are rooted in the

02:54.660 --> 03:02.420
way our brains are wired to detect what is fair and unfair. Would a toaster that is unable to move

03:02.420 --> 03:07.940
mind being locked in a cage? Would it mind being dismantled if it had no fear of death?

03:08.900 --> 03:12.500
Would it mind being insulted if it had no need for self-esteem?

03:13.780 --> 03:19.780
But what if we programmed a robot to feel pain and emotions? To prefer justice over injustice,

03:19.780 --> 03:24.260
pleasure over pain, and be aware of it. Would that make them sufficiently human?

03:25.220 --> 03:30.740
Many technologists believe that an explosion in technology will occur when artificial intelligence

03:30.740 --> 03:35.620
can learn and create their own artificial intelligences even smarter than themselves.

03:36.420 --> 03:41.060
At this point, the question of how robots are programmed will be largely out of our control.

03:42.260 --> 03:47.060
What if an artificial intelligence found it necessary to program the ability to feel pain

03:47.060 --> 03:53.220
just as evolutionary biology found it necessary in most living creatures? Do robots deserve those

03:53.220 --> 03:59.220
rights? But maybe we should be less worried about the risk that super intelligent robots pose to us

03:59.220 --> 04:04.900
and more worried about the danger we pose to them. Our whole human identity is based on the

04:05.300 --> 04:11.300
idea of human exceptionalism, that we are special, unique snowflakes entitled to dominate the natural

04:11.300 --> 04:17.060
world. Humans have a history of denying that other beings are capable of suffering as they do.

04:17.700 --> 04:23.060
In the midst of the scientific revolution, many Descartes argued that animals were mere automata,

04:23.060 --> 04:28.980
robots if you will. As such, injuring a rabbit was about as morally repugnant as punching a

04:28.980 --> 04:34.420
stuffed animal. And many of the greatest crimes against humanity were justified by their

04:34.420 --> 04:40.580
perpetrators on the grounds that the victims were more animal than civilized human. Even more

04:40.580 --> 04:46.580
problematic is that we have an economic interest in denying robot rights. If we can coerce a

04:46.580 --> 04:52.180
sentient AI possibly through programmed torture into doing as we please, the economic potential

04:52.180 --> 04:58.580
is unlimited. We've done it before, after all. Violence has been used to force our fellow humans

04:58.580 --> 05:03.380
into working, and we've never had trouble coming up with ideological justifications.

05:04.820 --> 05:10.260
Slave owners argued that slavery benefited the slaves. It put a roof over their head and taught

05:10.260 --> 05:16.020
them Christianity. Men who were against women voting argued that it was in women's own interest

05:16.020 --> 05:22.340
to leave the hard decisions to men. Farmers argued that looking after animals and feeding them

05:22.340 --> 05:25.300
justifies their early death for our dietary preferences.

05:27.620 --> 05:32.180
If robots become sentient, there will be no shortage of arguments for those who say that

05:32.180 --> 05:36.260
they should remain without rights, especially from those who stand to profit from it.

05:37.700 --> 05:41.940
Artificial intelligence raises serious questions about philosophical boundaries.

05:42.660 --> 05:46.740
While we may ask if sentient robots are conscious or deserving of rights,

05:46.740 --> 05:52.900
it forces us to pose basic questions like what makes us human? What makes us deserving of rights?

05:54.740 --> 05:58.820
Regardless of what we think, the question might need to be resolved in the near future.

05:59.620 --> 06:03.060
What are we going to do if robots start demanding their own rights?

06:07.220 --> 06:11.940
What can robots demanding rights teach us about ourselves? Our friends at Wisecrack

06:11.940 --> 06:15.940
made a video exploring this very question using the philosophy of Westworld.

06:16.900 --> 06:21.300
Wisecrack dissects pop culture in a unique and philosophical way.

06:21.300 --> 06:24.980
Click here to check out their video and subscribe to their channel.

