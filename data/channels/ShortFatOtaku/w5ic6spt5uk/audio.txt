Do you know who Palantir is?
I do.
Some people have referred to them as Stanford Analytica.
Do you agree?
Senator, I have not heard that.
Okay.
Do you think Palantir taught Cambridge Analytica, as press reports are saying, how to do these
tactics?
Senator, I don't know.
Do you think that Palantir has ever scraped data from Facebook?
Senator, I'm not aware of that.
Okay.
Mr. Zuckerberg, would you be comfortable sharing with us the name of the hotel you stayed in
last night?
Um, uh, no.
If you've messaged anybody this week, would you share with us the names of the people
you've messaged?
Senator, no, I would probably not choose to do that publicly here.
I think that may be what this is all about.
Here's what everybody's been trying to tell you today, and I say this gently.
Your user agreement sucks.
I'm going to suggest to you that you go back home and rewrite it.
Let's talk about that Facebook cryptocurrency that I brought up last video.
Libra.
Facebook launches cryptocurrency in bid to shake up global finance.
Digital currency will let billions of users make transactions, but is already facing opposition
from US lawmakers amid privacy concerns.
You know, for The Guardian, this related article here is pretty red pilled.
Facebook's Libra launch will extend its global domination.
I mean, I agree, but I guess it's lefty authoritative sources that are allowed to talk about
conspiracy theories nowadays and not regular plebs like us.
Facebook has announced a digital currency called Libra that will allow its billions
of users to make financial transactions across the globe in a move that could potentially
shake up the world's banking system.
Libra is being touted as a means to connect people who do not have access to traditional
banking platforms.
Yeah, this sounds like another variant of the whole financial inclusion thing I mentioned
in my Mastercard video last year, where these companies have the long-term goal of everybody's
financial transactions happening online so that they can more effectively control them.
I mean, really, when a credit card CEO tells you that cash is discriminatory, it doesn't
take a genius to realize they've got something up their sleeve.
With close to 2.4 billion people using Facebook each month, Libra could be a financial game
changer, but will face close scrutiny as Facebook continues to reel from a series of privacy
scandals.
And yeah, this is why I won't be using it.
I trust the randoms on eBay to not send me a bomb more than I trust Facebook with managing
my money.
I withdraw from PayPal almost daily nowadays because I don't trust them either.
US lawmakers were quick to raise privacy concerns about the new currency.
Shortly after Facebook's announcement, the Congresswoman and chair of the House Financial
Services Committee, Maxine Waters, called on the company to put a stop to the project
until Congress and regulators could review it.
She also called on company executives to testify before the committee.
Facebook has data on billions of people, and has repeatedly shown a disregard for the protection
and careful use of this data.
With the announcement that it plans to create a cryptocurrency, Facebook is continuing its
unchecked expansion and extending its reach into the lives of its users.
I've got to raise this question.
How is Libra a cryptocurrency?
Here's my very limited layman's knowledge on what a cryptocurrency actually is.
One, it's based on blockchain technology, making it extremely hard to regulate or interfere
with.
The blockchain was invented by Satoshi Nakamoto, which is probably a fake name, back in 2008.
The idea is that each block of data in the chain contains a cryptographic hash of the
previous block, along with a timestamp dating its generation and transaction data regarding
ownership of that block.
The ledger of the blockchain is available to all owners of a block via peer-to-peer
networking, the same basic tech as BitTorrent, ensuring that all people involved have the
same ledger.
P2P means that it's decentralized information.
If one person drops out, the ledger continues on through other users.
Because each block contains a record of previous blocks, it's also highly resistant to tampering.
New blocks in the chain are generated by mining, which is basically letting your computer run
algorithms to calculate the new data set for the next block, based on the hashes of all
the previous blocks nested within it, as glean from your copy of the blockchain ledger.
This means that as more blocks are generated, the more computational power it takes to generate
the next block, meaning that there is a level of scarcity regarding the theoretical number
of blocks.
This also means that all of those retards who spent hundreds of thousands of dollars
on GTX 1080s last year basically ruined their lives, because the more people who jumped
on the Bitcoin train, the costlier it became to actually mine the coins.
Using such rapid adoption of that technology, one of the many reasons that everyone who
kept their assets in Bitcoin lost everything.
But it's not just that a valid crypto has to be blockchain-based.
The second requirement is that it has to be freely traded at market value.
The price of Bitcoin fluctuates based on many factors.
The number of Bitcoins actually being bought and sold, the current number of miners as
I just mentioned, the current length of the blockchain, as well as various public trust
issues, like when CoinCheck got hacked and lost $530 million worth of its user's coin,
or when Facebook, Google, and Twitter decided to ban the use of crypto on their platforms.
And really, it's no surprise that Facebook banned the use of crypto back in March of
2018, if they were planning to make Libra all along.
John Todaro of TradeBlock has stated that Facebook's had Libra in the making for over
a year now, so of course they would go out of their way to ban their competition's
cryptos.
If it's tech-related and Silicon Valley can't control it, they will do anything
to stop it.
Libra, unlike actual cryptocurrencies like Bitcoin, will not be traded at market value.
In CTV's article, A User Guide to Facebook's New Crypto, they write,
Bitcoin is known for its wide price fluctuations, but the price of Libra is expected to be more
stable.
That's because Libra's value will be pegged to established currencies like the Canadian
dollar, the US dollar, or the euro.
It will also be backed by a reserve fund, whereas Bitcoin is not.
Facebook hasn't said what assets that reserve fund will be made up of, but its white paper
suggests it will include bank deposits and government securities in currencies from stable
and reputable central banks.
And this is why Libra is not a true crypto.
Its price is artificially set by the holder of most of the Libra in existence, in this
case Facebook.
And unlike Bitcoin, which holds value because of the inherent rarity that blockchain technology
and mining for new coin provides, Libra holds value because of the backing of big banks.
The article also describes the Libra Association, which Facebook co-founded with Mastercard,
Visa, PayPal, and Uber, as well as like 20 other companies, acting as a monetary authority
to regulate Libra.
Who here is surprised to see Thrive Capital and Stripe on this list, considering their
involvement in the Patreon purge?
No?
No one?
Didn't think so.
I don't know about you, but to me, private companies creating their own currency that
they centrally control independent of market value and then also controlling the regulatory
body for that currency smells like an absolute disaster waiting to happen.
Oh, and by the way, this is why I was also partially wrong in my Is Dlive a Scam video,
guys, and I'm very sorry about my failure on that one.
Dlive does use blockchain technology, but it uses it in its stream encoding, not its
Lino currency.
Using blockchain on a stream or a video service means that content is unable to be edited
after publishing, making it a strong defense against false DMCA claims and censorious,
vaguely defined harassment and hate speech guidelines.
The Lino currency Dlive uses itself, despite being tracked on crypto trackers, is not actually
a crypto.
It's still a waste of your money, because when you buy Lino with real cash and donate
the Lino to a streamer, when the streamer withdraws the Lino they get less money than
you put into it, making Dlive's claim that they don't skim off the top complete BS.
But they're not as bad as I made it sound in the video.
As long as you're not actually dealing in Lino, Dlive's a fine platform to stream on.
Sorry guys, my bad.
Back to Libra though.
If cryptocurrencies require both blockchain technology to track ownership and prevent
fraud, as well as free trading on the open market in order to ensure the coin actually
has value to people and not just the authority pegging the price like with China's Yuan or
Venezuela's Bolivar, then the Libra cannot, by definition, be a true crypto.
Blockchain tech will keep it organized, but if Facebook centrally decides the value controls
the supply and regulates the practices, then it's not a free currency.
But beyond economic problems, there's also the problem of public trust.
For example, Sargon posted on his Facebook, neutrally, that our good friend Tommy R was
right on Muslim prison gangs in the UK, and Facebook deleted the post for hate speech.
Nothing hateful was present in the speech, but they did it anyway.
Facebook, like all other big social media platforms, routinely deletes, deplatforms,
and depersons individuals who disagree with radical leftist politics.
These are not the people we want in control of the online financial system.
card cards' heinous censorship of jihad watch and Patreon's purging of alternative
voices is bad enough.
This has to be opposed.
Hey, none of us are surprised that a group called Women's World Banking is in on this
garbage right?
In order to meet the needs of the nearly 1 billion women globally who lack access to
financial products and services, financial institutions need capital from gender lens
investors who understand that investing in women can provide both a social and financial
return.
In other words, it's completely fine to build the corporate dystopia, as long as our
authoritarian CEO overlords are feminists.
Considering how Silicon Valley is basically trying to sync up our entire lives with their
central servers, and their complete inability to maintain even a semblance of political
neutrality in their actions, I find it absolutely reprehensible that these companies subsist
on the teat of the American government.
Google, Microsoft, Facebook, Apple, and Amazon get $2 billion in data center tax breaks.
Economic benefit unclear.
Oh yeah, a lot of American states have been trying to court these companies for warehouses
and data centers, only to realize later that a lot of this stuff is automated and doesn't
actually bring any jobs with it.
While the number of construction jobs generated for each facility is comparable to building
a factory or distribution center, an operating data center creates an average of just 30-50
permanent jobs.
The incentive packages can be quite outlandish, far exceeding any reasonable economic justification,
said Todd L. Cherry, director of the Center for Economic Research and Policy Analysis
at Appalachian State University.
Hey, here's an idea.
If companies take government money and operate some type of a public square as part of their
business like Google, Facebook, and Twitter, maybe they should be legally required to protect
its users' first amendment rights, and if they fail to do so, they don't get the grants
they apply for.
Seems reasonable to me.
I mean, just look at how much money is being wasted.
Available over at the public subsidy tracker Good Jobs First.
According to these guys, Facebook has taken in $332 million in state subsidies.
$150 million came from the state of Utah to build a data center in Eagle Mountain, producing
an estimated 30-50 jobs.
Another $150 million from Texas this time to build a data center at Fort Worth, with
no tracked data regarding jobs created.
This is ridiculous.
Another argument against big tech censorship is the whole Marsh v. Alabama case.
And I know I've talked about it on this channel before, so bear with me.
The town of Chickasaw, Alabama in 1946 was a company town, meaning the entire town was
privately owned by the Gulf Shipbuilding Corporation.
Gulf built the town and everything in it to service its business needs.
Work facilities, houses for their workers, shops, and basic services, all provided by
the company.
So when Miss Marsh began distributing religious literature on the sidewalk, she was asked
to stop, and eventually arrested for trespassing when she refused.
Gulf's argument was that they owned the entire town, including places it normally considered
public property, like streets, and so they could restrict speech however they liked.
However, the court ruled in favor of Miss Marsh, stating that if a private entity holds
a monopoly on the public square, they are legally obligated to behave as if the government
would when it comes to the rule of law, including free speech rights.
And to me this makes sense.
If a murder were committed in Chickasaw, the state police would still handle the case.
It wouldn't be handed off to a private police force even though the entire town was privately
owned.
Another lesson we can extract from Marsh v. Alabama is that companies with a monopoly
must behave responsibly, or the government will step in and either regulate them or break
them up.
Oh, and would you look at that, big tech is getting regulated because they won't behave
properly.
Who could have seen this coming?
Because this one seems to be the video where I admit all of my mistakes, I also made an
error in publishers versus platforms.
A pretty big one, in fact.
But it's also an error that everyone under the sun makes.
Under section 230 of the Communications Act, there's actually no definition of publisher
or platform, and there's no legal impetus for a platform to behave impartially.
In fact, as it's laid out in the Tech Dirt article, it's one thing for trolls and grandstanding
politicians to get 230 wrong, but the press shouldn't help them.
The law was actually designed to incentivize companies to censor its users.
Section B4 directly says that one of the policy goals of the law is to remove disincentives
for the development and utilization of blocking and filtering technologies.
And more importantly, section C2 makes it clear that section 230's intent was to encourage
moderation by taking away liability for any moderation decisions.
No provider or user of an interactive computer service shall be held liable on account of
any action voluntarily taken in good faith to restrict access to or availability of material
that the provider or user considers to be obscene, lewd, filthy, excessively violent,
harassing, or otherwise objectionable, whether or not such material is constitutionally protected.
In short, if a site decides to remove content that it believes is objectionable, including
content it finds to be harassing, there is no liability for the platform even if the
content blocked is constitutionally protected.
So yeah, we all got that wrong.
230 is designed to give companies a cover for censorship, not designed to prevent it.
In Professor Jeff Kosseff's book, The 26 Words That Created the Internet, a book documenting
the history of section 230 of the Communications Decency Act, it's written that the government
was spurred to act by the court case Stratton Oakmont, Inc. v. Prodigy Services Co., 1995.
In this case, the court ruled that online service providers could be held liable for
the speech of their users.
The court decided that because Prodigy provided content guidelines for users, enforced those
rules with moderators, and used the basic software of the time to automatically regulate
speech through word filtering, that Prodigy was making an active effort to be responsible
for the speech on its platform, and therefore was legally liable for the speech not caught
by them.
This court ruling, on its own, would have set a precedent forcing Facebook and Twitter
and the like to either not moderate anything or be liable for anything they miss.
But this wasn't the only ruling influencing this situation.
Professor Kosseff also talks about Cubby, Inc. v. CompuServe, Inc., 1991, a ruling in
which Cubby sued CompuServe for defamation because CompuServe's users were posting
negative content about Cubby.
Cubby's position was that CompuServe was liable for the content posted using its service,
and CompuServe's position was that it was not liable because it was a distributor and
not a publisher.
The court ruled that, as a distributor, CompuServe could only be held liable if it knew about
the content, but because CompuServe did not regulate its forms at all, it was not liable.
These two rulings, put together, created a problem for the burgeoning mid-90s internet.
Cubby v. CompuServe ruled that distributors of content who don't regulate what they
distribute aren't liable for the content specifically if they have no knowledge of
the content's existence.
Oakmont v. Prodigy ruled that any attempt to moderate an online community, even good
faith attempts, rendered the company legally liable for all content unmoderated.
This left the internet in a serious bind.
Companies had to either take responsibility for everything on their platform, a daunting
task with today's technology, let alone back in the 90s, or they had to willfully
blind themselves to their own service, to the point that companies weren't willing
to risk even benign forms of knowledge about what they themselves were actually doing.
This chilling effect caused a lot of companies who fashioned themselves as impartial distributors,
like CompuServe, to refuse to collect metrics about their users for the sole purpose of
offering a better product, like asking, how would you like to see our service improve
polls or something.
It also prevented them from policing content for legitimate and heinous breaches of the
law, like child pornography distribution.
It would have also made online shopping impossible had it existed back then due to the nature
of collecting relevant data from users in order to make a purchase.
If you want to know why mid-90s internet sucks so much, this is a big reason.
These companies were forced to keep themselves in the dark about their own practices.
Section 230 was, therefore, a compromise.
Rather than be responsible for everything if you curate, or force yourself to be blind
if you don't, it allowed internet companies to observe their users' behaviors while
not making them liable for those behaviors.
This was a groundbreaking decision that allowed the internet to flourish into what it is today.
230 gave internet companies the ability to regulate their users' content without being
liable for it, something that the early internet needed in order to survive.
And that's completely at odds with the public perception of 230 as the publisher versus
platform dichotomy, which has no actual basis in the law.
However, the internet has changed since 1996, and nowadays 230's protections are being
used to censor people out of the internet public square.
Thankfully, we're not the only ones who have clued into this.
Senator Josh Hawley is working on the Ending Support for Internet Censorship Act, which
modifies Section 230 to basically include the publisher versus platform thing that we
all thought I already had built into it.
Hawley's bill would task the Federal Trade Commission with certifying that tech companies
are approaching moderation in a neutral way, a requirement for any company with over 30
million monthly active users in the US, 300 million monthly active users globally, or
$500 million in global revenue.
Certification would require a supermajority vote, including at least one minority member,
and would occur every two years.
If a company over that threshold could not be certified, it would lose its Section 230
protections and be subject to intermediary liability litigation.
So basically, if the FTC determined that Facebook or any of the others is biased in moderation,
then 230 protections no longer apply, and they can be held liable for all the legally
dubious content on their platforms.
Can you imagine if Facebook is held liable for Christchurch?
Or for any of the millions of defamatory posts on its platform?
They get sued into oblivion.
But check out Big Tech's objection to this regulation.
The Internet Association, which counts Facebook, Twitter, and YouTube as members, describe
the legislation as misguided and destructive.
230 is the law that allows online companies to moderate and remove content that no reasonable
person wants online.
You just don't get it, do you?
You are not the arbiter of what is reasonable.
This bill forces platforms to make an impossible choice, either host reprehensible but First
Amendment protected speech, or lose legal protections that allow them to moderate illegal
content.
If this is First Amendment protected, you should not be stepping in.
You're forcing your definition of what is reprehensible onto everyone else.
Like it's, say, an axiomatic presupposition.
There's multiple angles we can take to stop Big Tech.
Changing 230 is one.
Marsh v Alabama and designating an online public square is another.
An Internet Bill of Rights declaring online accounts to be property and use of communication
services to be a right is another.
Pulling government funding for Big Tech that refuses to uphold the First Amendment is yet
another.
I started this video with Libra and ended it on free speech, but that's because they're
all related.
We've seen how poorly these people and these companies treat speech.
They will treat money the exact same way, if we don't oppose this here and now.
I don't trust Facebook with my money just like I don't trust them with my data and
with my speech.
I don't want to live in a future where I can't pay my bills because I said a naughty
word on the internet.
Oh, also?
Libra doesn't even work.
I don't trust Facebook with my money just like I don't trust them with my speech.
