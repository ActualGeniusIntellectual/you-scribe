start	end	text
0	1520	Hello, what's up?
1520	3720	Hey, how's it going?
3720	5380	I'm going to sound a little bit strange.
5380	7440	I'm in a different location right now.
7440	9920	How do I sound?
9920	11600	You sound good.
11600	12560	OK, that's good.
12560	13560	That's good.
13560	16240	Have you been?
16240	17940	I've been fine.
17940	19720	How have you been?
19720	20360	I'm pretty good.
20360	23000	I took a week off from YouTubing.
23000	24720	Nice.
24720	26200	Actually, over the course of the week,
26200	34800	I uploaded a series that it was me, Arch, Kibbs, Lilith,
34800	36400	and Taftach.
36400	39360	Taftach bowed out like 3 quarters of the way
39360	41040	through because she couldn't do it anymore.
41040	44480	But we watched Lord of the Rings, The Rings of Power,
44480	46960	season one, and like, Rift on it because it's not a very good
46960	47800	show.
47800	48960	But I released that.
48960	50200	Yeah, it's pretty bad.
50200	52840	But I released it over the course of my week off.
52840	54200	It was a pretty good week off.
54200	55000	Yeah.
55000	56160	That's cool.
56160	57960	Someone says I'm more muffled than normal.
57960	59880	Yes, I mean, this is a lot.
59880	61240	I got to just hold on.
61240	63560	Jesus.
63560	65320	Hold on.
65320	66520	I'm in a different location.
66520	68520	All my stuff's strange.
68520	74680	But yeah, so what's the TLDR and what you're doing right now?
74680	77000	I've only seen like a little bit of the stream.
77000	78080	What's going on here?
78080	81280	I'm reviewing my torture from the past two days, essentially.
81280	84320	The first piece of torture was the panel
84320	89040	that turned into a 3v1, and nobody else could get in.
89040	92200	And the second torture is the two hours of hate.
92200	95560	That actually ended up being more like two hours
95560	97200	of mild criticism.
97200	100640	Oh my gosh, thank you for the $10, Elle.
100640	102880	Oh, is that Elle from Death Note even?
102880	105040	It kind of looks like the, yeah.
105040	105760	Yeah, that's him.
105760	106680	Elle from Death Note.
106680	107180	Jesus.
110320	113880	So I guess my first question is, why
113880	117120	are you doing this to yourself?
117120	118800	Self torturing again.
118800	121080	You seem to do this regularly.
121080	123400	I think it's good for me to review things.
123400	130040	Like that panel where it turned into everybody versus me,
130040	132360	I thought I did worse on than I actually
132360	133980	did when I actually reviewed it.
133980	138400	I was like, oh, this wasn't bad at all.
138400	141280	And it made me feel a little bit better as well.
141280	143640	And then it's just good to go over things
143640	147120	and kind of see where you could put other things, how you
147120	149280	can improve stuff like that.
149280	150000	Oh, fair enough.
150000	150520	Fair enough.
150520	153120	It just also sounds like you're torturing yourself,
153120	155240	which probably isn't that good.
155240	156400	But I mean, hey, if you're.
156400	157560	Alt-right punching bag art.
157560	160280	Yeah, yeah, apparently I'm an alt-right punching bag,
160280	161800	apparently.
161800	163400	So that's another thing.
163400	167080	Yeah, I don't think I am, but.
167080	170160	Someone in your chat says, has Brove responded to Sunday yet?
170160	171440	Do you mean me?
171440	173440	I guess he means you, yeah.
173440	175160	I don't think you'd need to.
175160	176800	No, no.
176800	178120	You should just clown on him.
178120	179800	What I would do is just clown on him.
179800	181400	He's my favorite lolcow right now.
184280	186960	He seems to be kind of insane.
186960	188360	Just a little bit.
188360	189200	Yeah.
189200	194560	And he seems like, oh, man, I don't necessarily
194560	196400	know how similar they are.
196400	198960	But he seems to have a similar obsessive pattern
198960	201360	like Mr. Girl does, where he'll be
201360	204000	hyper-fixated for a little bit and then move on, you know?
204000	208240	You know, he used to be a huge Sargon fan, apparently.
208240	209520	That's actually really funny.
213040	217880	OK, so this is, I don't know about this current video
217880	219920	that you're about to watch, but the previous one
219920	224240	was all about the platforming drama, right?
224240	228800	So what's the TLDR on the Stardust platforming drama?
228800	231600	That I should care about the harm
231600	233400	that I put out more than I should
233400	235440	care about whatever benefits I think
235440	239280	I'm getting from my interaction.
239280	241280	At least that's what other people think.
241280	245120	I personally, like what you said about different frameworks
245120	248600	that we're operating in really resonated with me.
248600	251120	Last time we talked, I think, I don't know how long ago it was
251120	252880	when you said that to me.
252880	254280	But that really resonated with me.
254280	258160	And also, I think, I can't lie and say that I, you know,
258160	261400	like I know, TedLogic can do this.
261400	263560	He can just gig a chat, be like, I don't give a fuck,
263560	266480	and it'll be fine, right?
266480	270040	I can't really lie about it.
270040	271600	I think it would be dishonest for me
271600	276200	to say I don't care about harm that I can inflict at all.
276200	279320	Clearly, I care about some type of harm.
279320	283480	But as it is right now, any type of harm
283480	287880	that I could, that is possible for me platforming people
287880	293480	is outweighed by how much I love what I'm doing
293480	297600	and what benefits I think I'm getting from it.
297600	301600	And it just outweighs it every time for me.
301600	303760	There may be some harm there, but the harm
303760	308400	is just not enough for me to not do what I'm doing.
308400	310920	Just to be clear, what you're talking about
310920	314080	is when you'll talk to like Richard Spencer or somebody
314080	317000	else who's on the dissident right or something.
317680	319400	And you're platforming them.
319400	322400	And they're saying, these people, MindWaves
322400	326240	and whoever else it was in that previous video,
326240	330520	they're telling you that you're talking to Richard Spencer
330520	332680	or whoever.
332680	336920	You're allowing them to expose their ideas to your audience.
336920	338920	And so that's going to cause more harm than good
338920	339440	down the road.
344520	346600	Even if you were to accept that as true,
347360	349760	what is actually your take on that?
349760	352640	The idea that, oh, you talking to Richard Spencer
352640	354480	and let's say that you do exceptionally poorly
354480	356200	in a debate with him or something.
356200	358640	And so what ends up happening is your audience
358640	362160	is converted into neo-Nazis, right?
362160	364720	Yeah, or some people in the audience are, yeah.
364720	367000	Yeah, that's their view, right?
367000	370600	And what's your counterargument to that?
370600	373760	My counterargument is that I get better, right?
373840	376120	And I just do better next time.
377800	382240	My counterargument is that if they were that easily converted
382240	384440	then they weren't really mine to begin with.
386840	388720	Yeah, yeah.
388720	392480	See, I genuinely don't agree with the platforming arguments
392480	394360	and I'm a lot more like chud logic on this
394360	395440	where it's like, I don't care.
395440	396840	I'm here to have fun.
396840	398040	I'm here to do whatever I want.
398040	400680	I'm here to make some money in some senses.
400680	402400	So it's like, I don't care.
403400	406160	At the same time, like I don't even think chud logic
406160	409400	would say that I'm here to make money
409400	414160	by causing harm to other people by his own standard
414160	415600	of whatever harm happens to be.
415600	417600	I don't even think chud would say that, you know?
417600	419680	I think people genuinely don't think that they're,
419680	421680	that even if they are causing harm,
421680	423920	they don't think they are generally, you know?
425520	428600	Like if you were to talk to some like oil baron
428600	432200	who's destroying, you know, just destroying a forest
432200	435560	or destroying something to get oil and then sell it,
435560	437080	he's gonna say that, well, there's benefits
437080	438480	to getting the oil and selling it too.
438480	440800	And there are benefits to getting the oil and selling it.
440800	443200	He's just gonna have a different moral calculus, right?
445400	446800	And you can go back and forth on whether or not
446800	450560	like he's correct or actually, at some point you can't
450560	454880	because like, morality is one of those tough,
454880	456400	one of those really tough things to talk about
456400	458560	because at the end of the day,
458560	461760	everybody seems to be correct from their own point of view,
461760	462960	if you know what I mean.
465360	466200	Yeah.
467160	471600	Like, Sargon and I have had a bunch of morality arguments
471600	474720	over the past couple of years in private, in private.
474720	477560	And a lot of it was like just reading up
477560	479640	on like certain philosophy and certain ideas
479640	482080	and what morality is and how it should be structured.
482080	485920	And it's just that you realize that like,
486960	490680	you drill down to a point where you understand
490680	493960	that everything is just, it's all just how you feel
493960	497240	about it and there's no real moral calculus at all,
497240	498400	which is kind of like a black pill,
498400	499960	but it seems to be true.
499960	500800	You know what I mean?
500800	502080	Yeah.
502080	504880	I mean, if it's true that these things have a risk,
504880	506440	so does everything else.
506440	508440	Like everything else has a risk.
508440	512480	And at the end of the day, is that risk worth it for you?
512480	516880	And I'm gonna answer like, with what I'm doing, yes.
519440	524120	And it's worth it because not just because of the benefits
524120	527120	I get from it, but because I genuinely enjoy.
527120	530880	And there are very few, I love making content,
530880	535880	but there is very little content that I enjoy as much
536160	538080	as like sitting down with people
538080	541480	who I'm not supposed to sit down with,
541480	542320	and having a conversation with them.
542320	544680	To be fair, I'm the same way, yeah, that's, yeah.
544680	547640	It's very, there's so, I love it so much.
547640	552640	And it's like, people are asking me to care so much
553040	556600	about this potential for harm,
556600	560520	that I stopped doing something that I like deeply love
560520	563120	or that I start doing it less, you know?
563120	566520	And I don't think that's fair though.
566520	568400	No, I know exactly what you mean.
568400	569280	Someone in the chat said,
569720	571360	what does this high school take?
571360	574520	So here's, it's not quite a high school take.
574520	579520	It's like, you know, when you're young,
579960	582640	most young people, we're talking like under 10 years old,
582640	585080	like really young, they tend to operate under
585080	587760	like some kind of deontological frame, right?
587760	590120	If they're religious, if they're raised by religious family
590120	592520	or just, you know, rules-based ethics,
592520	595640	you follow what your teacher says, follow what your parents
595640	596840	say, whatever, right?
596840	598960	And then like, generally, as you start thinking
598960	601840	about these systems a bit more,
601840	604160	as you hit like your teen years and your twenties,
604160	606480	that's when you start getting like consequentialists, right?
606480	609040	And God, I'm reminded of like,
609040	610880	Xanderhal talking to Lauren Souther.
610880	611720	Did you watch that?
611720	613800	It was like a year ago or six months ago, whatever it was?
613800	614640	Yeah, yeah.
614640	616960	And Xanderhal tried to hit her with like,
616960	618560	are you a consequentialist?
618560	620900	Like just asking that question openly several times.
620900	623720	And Xanderhal doesn't seem to understand,
623720	625080	not to just throw shade on him.
625080	626760	He's not here, but I also don't care.
627720	630600	But like, he seems to be at that like early twenties.
630600	631560	I think he's in his early twenties.
631560	634600	So he's at that early twenties stage where it seems like
634600	638120	ruthlessly going after ends in defiance
638120	641560	of rules-based morality or in defiance of tradition
641560	644640	or in defiance of whatever seems to be the best thing to do
644640	646440	because what you want is to improve the world.
646440	648000	So, you know, fair enough.
648000	650280	But he just doesn't understand that like,
650280	652840	and what a lot of people I've noticed on the left,
652880	657800	what they don't understand is basically that
657800	660440	in order for any sort of consequentialist
660440	663260	or any sort of utilitarian ethics to work,
663260	667400	you already have to have defined what the good is first
667400	670120	in order to like be able to point out a good end,
670120	672080	if you know what I mean.
672080	674120	So it's like, well, I think I might've,
674120	676960	I don't know if I made this comparison with you
676960	678800	or with somebody else, but I was saying like,
678800	683480	you could have a consequentialist ISIS fighter
683480	685460	who believes that it's a good end
685460	688120	to throw a gay person off of a rooftop
688120	689720	and to him, that's a good end.
689720	691760	And so he can actually give you a list of good ends
691760	695160	that comes out of having one less gay person in the world.
695160	698160	And then it's just like, well,
698160	701280	how did he get using the same framework,
701280	704240	a completely different end than you or I would get to?
704240	705360	And it's because, well,
706360	711360	any sort of moral calculus is based on a foundation
712160	715520	of what is basically just your moral intuitions,
715520	717240	just your feelings, right?
717240	719200	So like, you and I will say,
719200	720600	well, we shouldn't kill gay people.
720600	722800	And that guy might say, well, we should kill gay people.
722800	725320	And then the only real difference between us
725320	729280	is that we feel one way and he feels a different way.
729280	732960	And at that point, it's hard to reconcile
732960	734400	different morality, you know what I mean?
734960	736760	It's, there's like a,
736760	741000	you're just not going to communicate
741000	743800	with the other person, I guess, yeah, so.
743800	746920	Yeah, and I think the last time we talked,
746920	748640	you were playing, I think, Dark Tide,
748640	750680	and I was trying to cheer you up about something or other.
750680	752760	And I basically said that a lot of people
752760	756280	who are like extremely progressive,
756280	761040	or they are, or they're like socialist or something,
761040	763120	some kind of revolutionary socialist,
763120	768120	they tend to view every single action
768800	770680	through a moral framework that's like,
770680	775040	well, how can I advance my political cause?
775040	777040	And so if you're not advancing a political cause
777040	780400	when you're doing, taking any sort of step anywhere,
780400	784840	especially in public, then you're doing something bad, right?
784840	785680	So if you're-
785680	787440	Yeah, how can I make the world more left
787440	790760	is I remember what you said specifically about it, yeah.
790760	793040	Yes, but here's the thing.
793920	795920	If you don't value making the world more left,
795920	798120	or at least you don't value it as much as they do,
798120	798960	well, then you're operating
798960	800880	from a different moral framework, right?
800880	803520	Yeah, and I don't value it as much as they do.
803520	808520	I don't value, I value this meaningful conversation
810120	813520	with somebody more than I value,
813520	818520	worrying about some harm that I'm inflicting
819360	823160	into the world through it.
823160	824000	I don't know.
824000	826880	And yeah, I don't know if that makes sense, but-
826880	827720	No, it does, it does.
827720	830600	And that's probably what I would tell people like mine way,
830600	833120	which is just like, listen, you have a moral framework
833120	835360	such that you view things this way,
835360	837080	but I don't share that framework.
837080	840840	And to me, the greater good is having these conversations
840840	842240	compared to the possibility,
842240	846400	the admittedly very small possibility that somebody on,
847240	850240	you know, considering your audience, considering you,
850240	852640	considering the relative size of your stream
852640	854520	that you're going to like cause the Third Reich
854520	856080	is next to 0%.
856080	858800	So like, it's not much of a big deal, you know?
858800	861600	There's no actual harm being done here.
861600	864320	And that's the case with almost all platforming arguments.
864320	868320	You know, until you get to like destiny or bigger,
869240	871800	or like a million subs on YouTube,
871800	873440	like a Sargon or something,
873440	876400	until you get to like these really big names and larger,
876400	878600	the platforming argument like makes no fucking sense.
878600	881880	Like, you know, how much Nazism are you actually spreading
881880	884680	on like a 20 view Twitch panel stream?
884680	887200	Like fucking none, you know what I mean?
887200	888600	It's ridiculous.
893920	896040	There's also one other thing I've been thinking about.
896040	897720	I was thinking of, it kind of came into mind
897720	899960	as I was watching you talk about this.
900480	905480	The third main moral framework is virtue ethics.
905960	908600	And you're familiar with virtue ethics, right?
908600	909680	Not really a whole lot.
909680	912680	I'm not really familiar with ethics as a whole.
912680	913520	Okay, okay.
913520	916080	So yeah, so the TLDR is that consequentialism
916080	917880	is goodness is good ends.
917880	921760	The deontological is goodness is good rules.
921760	925160	And then virtue ethics is goodness is good habits.
925160	927480	And the idea of virtue ethics is basically that
927880	931320	things that are good are things that cultivate
931320	936320	good moral character in how you behave, right?
937240	940680	In the kind of the quality of person that you are.
943280	947440	And so I know Sargon is on a big virtue ethics art
947440	949880	right now, destiny started up in a virtue ethics art
949880	951160	like last year.
951160	953740	I think destiny started by reading CS Lewis.
955160	956440	But there's a famous quote,
956640	957720	I don't think it's a CS Lewis quote,
957720	959720	but there's a famous quote that says that
961440	966440	it's something that man is both the marble and the sculptor.
967040	970640	And the idea is that every action that you take
970640	974180	also acts on you and you change as a result of it, right?
975160	979160	And I think everyone has the experience
980800	984080	of being like a bit trepidatious about doing a new thing.
984080	985540	But then as soon as you do it,
985540	986580	you realize, oh, I can do it.
986580	988660	And then you do it regularly.
988660	992080	Smokers, for example, drug users, people who drink alcohol,
993980	995820	but also more positive behaviors as well.
995820	997940	And you're scared about breaking out of your shell,
997940	1000340	you break out of your shell, oh, it's actually not so bad.
1000340	1002300	What's happening psychologically is like
1004660	1006900	new pathways are being formed in your brain
1006900	1008700	that makes it easier to do those actions
1008700	1010500	a second, third, fourth, fifth time.
1011500	1015260	And so what ends up happening is that
1017540	1022540	good ethical behavior is whatever builds
1023540	1026380	virtuous habits in your person.
1026380	1027940	And that can be related to good rules
1027940	1029760	and it can be related to good ends,
1029760	1031980	but it's also related to good habits.
1034380	1036680	And the reason I'm bringing this up,
1036680	1037980	the reason I'm bringing this up
1037980	1040220	is because even though a lot of left-leaning people
1040820	1042700	are like strict consequentialists,
1042700	1045960	the entire argument regarding platforming
1045960	1047540	is a virtue ethics argument.
1048360	1052420	And a lot of lefties tend to reject virtue ethics
1052420	1054260	because to them it's all about getting the goal,
1054260	1055220	getting the result.
1055220	1057540	You know, it's all about chasing after
1057540	1059360	what makes the world a better place
1059360	1061540	in a very like ruthless manner.
1061540	1065660	And you know, the most extreme leftists in history
1065660	1069220	always ended up committing like these huge political purges
1069260	1071460	because they were after the goal,
1071460	1074360	regardless of what kind of monster it turned them into.
1075980	1078380	I think that's, you know, there's a common critique
1078380	1081320	of the authoritarian left on the right.
1081320	1082860	And it's that they always believe
1082860	1084760	that it's one more purge until utopia.
1087080	1090940	But the platforming conversation,
1090940	1093080	the platforming argument is like,
1094420	1097700	it's a virtue ethics argument because the implication
1097700	1100020	is that your audience will turn into Nazis
1100020	1102300	through exposure to these new ideas.
1102300	1105260	But if your audience were actually strict consequentialists
1105260	1106940	then it wouldn't matter how much exposure
1106940	1108620	to these ideas they get
1108620	1111100	because they're always going to go for the results.
1111100	1113380	And if they're good results, they're good results, right?
1113380	1116620	So it's funny to see,
1116620	1118660	like I don't think these people have fully thought
1118660	1122140	through their ideas because it's funny to see them,
1122140	1124700	like it's funny to see them use logic
1124700	1127580	that they would never use in any other situation.
1128460	1130540	That is a really interesting point.
1132940	1137200	Is there a way that you can, well, I mean, I guess,
1140700	1142580	it's super interesting that it's like
1142580	1145660	a virtue ethics argument, the platforming argument.
1147420	1150700	I feel like it's a mix of consequentialist and virtue,
1150700	1152340	isn't it?
1152340	1154180	Well, here's the thing, at the extremes,
1154180	1156660	all three of the ethical systems blend into one,
1156660	1159860	which is why talking about them is kind of meaningless.
1159860	1160700	You know what I mean?
1160700	1165540	Like, I mean, if you talk about deontological ethics,
1165540	1167620	the common critique that pretty much everyone knows
1167620	1169740	is like, well, what if you have a bad rule?
1169740	1171300	It's like, well, good equals good rules.
1171300	1173380	Well, if you have a bad rule, should you follow it?
1173380	1178380	And like, well, if you live in a system of honor
1178420	1179860	or like a caste system or something
1179860	1182260	and you have to kill somebody who's innocent otherwise,
1182260	1183180	I was like, should you follow that?
1183180	1184780	Well, the answer seems to be no, right?
1184820	1188140	You push deontological ethics to their limit,
1188140	1189940	they seem to break pretty easily
1189940	1192580	when it comes to committing immoral actions.
1192580	1195420	But at the same time, consequentialist ethics
1195420	1197060	has a very similar problem.
1197060	1200060	And I've heard it said, I've heard it said a few times,
1200060	1202660	like in a pure consequentialist world,
1202660	1205060	no one would ever go to a hospital, right?
1205060	1206820	And the reason you wouldn't go to a hospital
1206820	1210140	is because like just per the strict moral calculus,
1210140	1213140	you can go into a hospital for like a cold
1213140	1216620	and then in the hospital are like 10 patients
1216620	1220680	who could all use your organs.
1220680	1222980	And the moral calculus is, well, guess what?
1222980	1225580	They'll just kill you, take your organs,
1225580	1227700	save these 10 lives, one life versus 10, right?
1227700	1230100	The moral calculus weighs out that that's a moral action
1230100	1232100	in a purely consequentialist sense.
1232980	1234020	And so it's like, well, fuck,
1234020	1235860	what kind of world do you build
1235860	1238560	when you have that kind of society?
1238560	1240300	Well, it'd be a terrible one, right?
1241300	1246300	So, and then you get to basically you reach a point
1247260	1250700	where you realize that the limits of each ethical system
1250700	1254100	are shored up by the other two ethical systems, you know?
1254100	1256060	Yeah, yeah, I can see that now, yeah.
1257300	1262300	And I did a video, a video like a year and a half ago
1262860	1264500	or something and the TLDR of it
1264500	1267160	was that consent is a deontological concept
1268120	1270440	because consent is a set of rules.
1270440	1273020	It's rules-based ethics, right?
1273020	1275960	Like if, you know, you can use sexual consent,
1275960	1279160	you can use consent to working in a job
1279160	1280680	or consent to whatever, right?
1280680	1281880	Anything in life, right?
1283560	1287560	And basically, if you're consenting
1287560	1289720	to whatever it is you're consenting to,
1289720	1291200	you're laying out a set of rules and you're saying,
1291200	1293280	okay, well, I'm going to do X, Y, Z
1293280	1295480	and you're going to do for me, A, B, C
1295520	1297800	and we're not going to violate these rules
1297800	1300140	because you don't want to violate the consent
1300140	1301720	of your partner when you're having sex with them
1301720	1305200	or violate your employer-employee relationship,
1305200	1307720	whatever it happens to be, the contract, whatever it is.
1307720	1310360	So consent is a concept
1310360	1312720	that comes out of deontological ethics
1312720	1316480	and I've seen people, again, on the left
1316480	1319820	like hate deontology so much.
1320800	1324920	And there's this view on the right as like,
1325200	1326880	well, how come there are so many leftist sex pests?
1326880	1327720	How many?
1327720	1328540	Like, how come?
1328540	1329380	Why, why?
1329380	1330760	And I don't know if there actually are that many or not,
1330760	1334080	but there are at least a few like high profile public ones.
1334080	1336080	And it's like, well, why are there?
1336080	1341080	And it seems to be the case is that if you have no sense
1341260	1343800	of deontological ethics in your ethical system,
1343800	1346480	then there's no reason to ever respect consent
1346480	1349320	because consent doesn't exist in consequentialism, right?
1349320	1352800	Like in a purely consequentialist sense, you know,
1352840	1354840	how much money could I be offered
1354840	1357040	to rape my girlfriend, right?
1357040	1359320	Well, you can just keep jacking that number up
1359320	1362040	until it hits a point where I should just do it
1362040	1364520	because I can get more good out of it
1364520	1366000	from having that much money to do more good
1366000	1368880	in the world with than not, right?
1368880	1371320	So in order to object to that scenario,
1371320	1374080	you have to go outside of consequentialism.
1374080	1376520	It's, this isn't exactly
1376520	1379000	like a super entertaining conversation.
1379000	1379840	Sorry, chat.
1379840	1381000	It's helpful.
1381000	1381840	It's helpful.
1381880	1383000	Chat, shut up.
1383000	1385880	Okay, seriously, this is helpful.
1385880	1387120	Sorry guys, sorry.
1389600	1393040	No, I think it is very helpful.
1393040	1396520	So that is something that's interesting.
1396520	1397920	And I think maybe I need to brush up
1397920	1399560	on what you're talking about,
1399560	1402480	these different like ethical frameworks and stuff
1403360	1404200	or whatever they're called.
1404200	1405040	The best thing you can do,
1405040	1407280	the best thing you can do for like almost any of this
1407280	1409080	is just Wikipedia it, you know?
1409080	1410640	Like I do a fair amount of reading
1410960	1412120	because I like to read.
1412120	1414040	And like for some like political topics,
1414040	1415080	especially if you're talking about fascism
1415080	1416680	because it's such an old idea
1416680	1419400	and it's like, it was around for like 30 years
1419400	1420400	and it vanished.
1420400	1421880	So like for that you have to read.
1421880	1423240	But for a lot of these other topics
1423240	1425640	that are still like talked about today,
1425640	1428920	Wikipedia articles are very accurate.
1428920	1430000	You know what I mean?
1430000	1431960	Okay, yeah, I'll take a look at that.
1434840	1435680	Yeah, I will.
1435680	1436520	Thank you for that.
1436520	1438240	I think that will actually help my argument.
1438800	1442280	If I dive into those different ethics things more,
1442280	1444200	I will definitely be able to argue better.
1444200	1446800	So for example, like you could,
1446800	1448440	when someone like Mindwave says like,
1448440	1449560	well, don't you think you have a responsibility
1449560	1451540	to platform whatever, right?
1451540	1454240	You could do the chud logic root of I don't care giga chad.
1454240	1455080	But you could also say,
1455080	1457000	listen, I think the greater good
1458200	1463080	is exposing these ideas and hopefully debunking them.
1463080	1464720	But even if I can't debunk them,
1464720	1466840	the greater good is in having the conversation
1466840	1468800	because free speech itself is a virtue.
1468800	1470840	Free speech itself is a virtue.
1470840	1474440	And enforcing those virtues,
1474440	1475360	especially in a climate
1475360	1477440	where they're not really being upheld anymore,
1477440	1478960	at least not right now,
1478960	1480560	that's a greater good than any harm
1480560	1483300	that could come of these ideas spreading.
1483300	1485240	And then you could also say that,
1485240	1486960	well, the greater good is also
1486960	1489280	that you hone your own skills.
1489280	1490120	And you say, well, you know,
1490120	1493000	even if one of my audience turns into a neo-Nazi
1493000	1495500	because I lost a debate against Richard Spencer,
1495540	1497460	well, I'm now a better debater for it.
1497460	1500020	And that seems to be like a worthy trade off
1500020	1502260	because now I'm better, you know?
1502260	1506540	And oftentimes, like a lot of these,
1509020	1512860	they're frankly just kind of like these bullying arguments.
1512860	1514660	They seem to be easily brushed away
1514660	1518220	by appeals to self-improvement in my experience.
1519260	1520840	Interesting.
1520840	1522300	That is really helpful.
1523300	1524420	Somebody in your chat says,
1524420	1527020	force mind waves to prove that it's bad.
1527020	1529380	I mean, mind waves can pretty easily prove
1529380	1530940	it's a hypothetical bad, right?
1530940	1534140	Like the logic tree is there.
1534140	1534980	Oh, you refused?
1534980	1535820	Really?
1535820	1536640	It's easy to prove.
1537580	1539380	I mean, but it's easy to prove,
1539380	1541540	but it's also easy to debunk, right?
1541540	1542580	Yeah.
1542580	1543980	So like he could say something like,
1543980	1545280	listen, you know,
1545280	1547060	Stardust platforms Richard Spencer,
1547060	1549380	Richard Spencer converts one of Stardust audience.
1549380	1551580	The world is now made incrementally worse
1551660	1553580	because there's one more Nazi in the world.
1553580	1555180	Like there's the logic, right?
1556100	1558180	And then you could say, well,
1558180	1559500	even if that's the case,
1559500	1561520	there's so many other benefits to it.
1563340	1565100	And no, no offense,
1565100	1567500	but you're not like a 10,000 viewer streamer or something.
1567500	1569740	So there's, so the drawbacks aren't really there.
1569740	1570660	You know what I mean?
1570660	1574980	Yeah, they were, yeah.
1574980	1576620	Anyway, I figured I'd just come on
1576620	1578180	and talk to you for a little bit
1578180	1580580	because every time I've tuned in to your stream
1580580	1581420	like the past few,
1581420	1582580	it seems like you're going through
1582580	1584420	some sort of struggle session.
1584420	1586720	Some sort of self-flagellation, yeah.
1589020	1591680	And the last time I talked to you,
1593180	1595020	when you were playing Darktide,
1595020	1597120	you also seemed down and I'm like, Jesus,
1597120	1599180	this is like the Stardust depression arc.
1600980	1603740	I think I've been a little bit more unsure of myself
1603740	1606300	recently in the past few months,
1606300	1608440	but I think I'm coming out of it.
1608480	1611360	I think we all get into funks for a little bit.
1611360	1612440	Oh yeah, me too, me too.
1612440	1615360	Yeah, I know I used to be much more confident
1615360	1618540	as a person several months ago.
1618540	1619380	And then I don't know,
1619380	1621280	the past couple of months have been
1621280	1624520	kind of like a Stardust no confidence arc.
1626680	1629560	And I think I'm coming out of it now, so yeah.
1629560	1632480	Is that because of mind waves or something else?
1632480	1634080	I think it's just compounding things.
1634080	1636360	I've just had like a whole bunch of things going on,
1636360	1637680	so yeah.
1637840	1638960	Okay, all right.
1638960	1639800	Yeah.
1639800	1641840	Yeah, I mean, I've had like IRL things
1641840	1643680	like unrelated to anything I do online,
1643680	1646080	also screw up what I'm trying to do.
1646080	1647560	It happens all the time, you know?
1647560	1648920	Yeah.
1648920	1650280	Yeah, I think you just have something
1650280	1651480	that kind of shakes you
1651480	1654880	and kind of shakes your reality for a little bit.
1654880	1658000	And then you think, can I trust my reality
1659740	1661480	the way that I thought I could?
1661480	1663560	And you're unsure of it for a really long time.
1663560	1665280	And then you realize that,
1665280	1667760	well, that was kind of like a freak accident.
1667760	1671520	So I have to like trust myself
1671520	1676320	or I won't be able to do anything again, so yeah.
1676320	1679000	Yeah, and a lot of that is just gonna be practice too,
1679000	1679960	you know?
1679960	1681640	Yeah, yeah.
1681640	1683280	Someone in your chances at this point,
1683280	1685520	I'm sure only mind waves cares about it.
1685520	1686960	At this point, the only appropriate action
1686960	1688240	is to bully him.
1688240	1691200	Well, maybe not bully him, maybe just ignore him.
1691200	1694240	Because I think I heard through the grapevine
1694240	1696520	he wrote a manifesto about you, is that true?
1696520	1697760	Yeah, yeah, he did.
1697760	1701120	I asked him for timestamps on like specific things
1701120	1703960	within this interview that I did that he didn't like.
1703960	1705880	And he said he put them,
1705880	1708480	but I've looked at like several sections
1708480	1713480	of this platforming manifesto or whatever.
1717600	1720960	And I don't see it.
1721960	1724520	I think he said that it's in a link in here somewhere,
1724520	1727840	but I'll have to look through the links and stuff and see.
1727840	1730160	So, yeah.
1730160	1733760	So it's not as well made as like a destiny manifesto
1733760	1736360	where like everything's sourced, nothing like that?
1738360	1741120	No, he sources me a bunch.
1741120	1743400	So he sources, yeah.
1743400	1747240	He just makes it all about me,
1747240	1750520	which is like, yeah, really targeted.
1750920	1754480	So, and then he's just been in,
1754480	1757000	he's been kind of dishonest about me, I feel,
1757000	1760160	and mischaracterizing me a whole lot, I feel.
1762560	1764440	Were you guys friends before this?
1764440	1766680	We were friendly, I think, we were friendly.
1768680	1770200	It always sucks when that sort of thing happens
1770200	1771680	and it's over, eh?
1771680	1773520	Yeah, yeah.
1773520	1776080	Because you had a drama with Mr. Girl, didn't you?
1776080	1778320	I only barely knew about this.
1778640	1780440	Were you guys friends before that too?
1781680	1782520	Yeah.
1783560	1784400	Yeah.
1784400	1785240	Oh, geez.
1786800	1787640	Man.
1789440	1790880	It is what it is.
1790880	1791800	Yeah, it always sucks
1791800	1792800	and that's what I think happens, right?
1792800	1795960	Like here, let me tell you a story
1795960	1798120	and it'll be a short story.
1798120	1798960	Let me tell you a story
1798960	1801640	and see if it sounds familiar to you, okay?
1801640	1806640	So I started doing a podcast with a friend of mine in 2017.
1807040	1807880	All right.
1808920	1811520	We had a good time, you know, we had a good time.
1811520	1815000	But by the time like 2021 rolled around,
1815000	1819800	he had been like hyper radicalized by COVID.
1819800	1823920	He's in the UK and British lockdowns
1823920	1826080	and restrictions were significantly more strict
1826080	1827480	than in America or Canada.
1828360	1829640	And he was also like,
1829640	1834640	he had built up this persona of himself.
1835160	1837440	Well, it wasn't a persona, it was real, it was real.
1837440	1838840	He wasn't faking it.
1838840	1840480	He had like an engineering job
1840480	1843520	and he would like, he'd be flown out by companies
1843520	1845400	that he would work with to go to like,
1845400	1846960	to go to the States, go to Turkey,
1846960	1850000	go to like various places just to do work, right?
1850000	1853680	And he had a lot of money, he had a lot of travel time.
1853680	1856720	And he kind of built up this image of himself
1856720	1858880	where he would be the guy that would like fly
1858880	1862560	into some foreign place for a job.
1862560	1864400	He'd have some fun there on the side.
1865440	1866680	If he had internet friends there,
1867280	1868680	he'd be the guy that would go and visit
1868680	1869680	and be like, hey, I'm here.
1869680	1871080	And then they'd go to the bar,
1871080	1873520	then he'd like throw some money around.
1873520	1874440	He'd be the center of attention.
1874440	1877240	And then he would fly off.
1877240	1881520	That was kind of the life he had built for himself.
1881520	1883480	And then he was grounded and lost his job
1883480	1886600	and lost everything during COVID lockdowns.
1886600	1887440	He kept his house
1887440	1889280	because he inherited his house from his dad.
1889280	1893840	And then he spent like a year and a half
1893880	1897120	locked down in this house with no job,
1897120	1902120	a pile of cocaine, two trans girlfriends,
1902240	1907240	one of whom was an actual neo-Nazi
1907520	1910080	and the other one who was an anarcho-capitalist.
1910080	1915080	And so he's got these two GIFs
1915240	1917440	doing lines of Coke off his dick.
1917440	1921160	And they're like reading him all of this crazy,
1921160	1922960	this crazy political theory.
1923000	1925160	And this guy radicalizes like fucking crazy.
1926320	1931000	And as he radicalizes, I don't.
1931000	1932560	Sargon does, but not nearly as much
1932560	1933960	and not for the same reasons.
1933960	1936920	Arch doesn't, V doesn't, Kibbe doesn't.
1936920	1941800	None of us in our circle radicalize at all, really.
1941800	1945040	And he gets to the point where he's so fucking lost
1946160	1947960	and he's so fed up with all of us
1947960	1949640	that he leaks all of our DMs.
1950600	1953440	And it was a huge drama on our side of the internet.
1953440	1954960	And so we all cut him out.
1954960	1957240	We kicked him out of our private circle.
1957240	1958560	I stopped the podcast with him.
1958560	1961120	It was a big fucking blowout.
1961120	1966120	But like I've heard that story repeated so many times.
1967560	1970680	Like I think Destiny had a podcast with someone
1970680	1972060	like five years ago that blew up
1972060	1973960	because like he got backstabbed.
1973960	1975640	Destiny got backstabbed by Mr. Girl,
1975640	1977600	like backstabbed by Vaush and Hassan.
1977600	1981760	Like Sargon has been backstabbed by people several times.
1981760	1986760	Like it just seems to be a thing in these online spaces
1987080	1988360	where there are just some people
1988360	1990780	who for whatever reason can't handle it.
1990780	1992960	And then they, like it gets into,
1992960	1994700	it turns into like high school drama.
1994700	1995800	You know what I mean?
1996680	1998160	Yeah.
1998160	1999000	I think so.
1999000	1999820	And it doesn't matter like,
1999820	2002340	it doesn't matter what political side we're talking about
2002340	2006120	or what groups, what, it doesn't matter any of it
2006160	2009300	because they all seem to happen like roughly the same way.
2009300	2010140	You know?
2010140	2010960	Yeah.
2012680	2014640	So fuck, you know, I know the feeling
2014640	2016880	of like thinking that you're friends with someone
2016880	2018480	and then like watching it all just blow up
2018480	2021120	because they put the knife right in your back.
2021120	2022220	You know what I mean?
2022220	2023560	Yeah, yeah.
2023560	2024840	It's never a good feeling.
2024840	2028200	But also like making a misjudgment yourself, right?
2029720	2032880	Making a misjudgment on somebody's intentions
2032920	2037220	or whether they're capable of treating you a certain way.
2038160	2043160	It also changes like your sureness in the future on things.
2048240	2049760	Yeah, yeah, that's for sure.
2049760	2052360	Like I spent like a year giving him
2052360	2053600	the benefit of the doubt.
2054600	2059600	And he just didn't go anywhere, you know?
2059600	2061000	And Sargon's been backstabbed enough
2061000	2064560	that like he really doesn't want to like,
2064560	2066900	he has like his business going, he has his employees,
2066900	2069000	he has his friends, and I'm just like,
2069000	2071560	hey, Sargon, you should talk and also aerate sometime
2071560	2073160	because she's actually really cool even though you guys
2073160	2074440	would obviously disagree on a lot of things.
2074440	2076560	Like she's good faith and she's intelligent
2076560	2078560	and you guys have a good conversation.
2078560	2082400	I've been like, sorry, you should talk to Taftach
2082400	2084320	because Taftach is like a right winger
2084320	2086200	and she's read neoreactionary literature
2086200	2087040	which you've been reading
2087040	2088620	and like you guys have a decent conversation.
2088620	2092420	And like Sargon's been very like cautious
2092420	2095940	about talking to new people because he's had so many people
2095940	2098960	just knife him in the back, you know what I mean?
2098960	2101580	Yeah, yeah, for sure.
2101580	2103420	Someone in the chat says, who cares about Sargon?
2103420	2105340	Sargon's made his comeback, man.
2105340	2106180	Like for real.
2106180	2107540	Yeah, it seems like he's doing well.
2107540	2110360	Yeah, he doesn't use the Sargon channel anymore
2110360	2115360	but he opened up a news outlet called the Lotus Eaters
2116200	2120920	and his couple of channels are doing really well.
2120920	2122160	He has some associated YouTube channels
2122160	2124400	are doing very well, but like his website is booming.
2124400	2125840	He's got like a dozen employees
2125840	2127040	and they're all like making,
2127040	2129040	they're all writing articles, they're all doing research.
2129040	2131360	Like, no, Sargon's doing very well.
2131360	2133560	He just doesn't call himself Sargon anymore.
2135640	2137480	Yeah, damn.
2137480	2138320	Yeah, I know.
2138320	2140120	It was so weird to have him covering stuff
2140120	2140980	that I was involved in.
2140980	2143120	I was like, bro, what the fuck?
2143120	2143960	But yeah.
2143960	2144800	What was that?
2145240	2146080	What did he cover?
2146080	2148400	It was the Ana stuff.
2148400	2149560	Oh yeah.
2150400	2152040	He had no idea what was going on.
2152040	2153860	He was like calling me like a leftist
2153860	2156400	who's incapable of seeing their own flaws.
2156400	2157760	And I was like, damn bro,
2157760	2160720	like you got all that from Ana crying about me.
2160720	2163760	Like, yeah.
2163760	2165640	I didn't see, I think I've heard,
2165640	2170640	like I heard that the take on the Ana stuff
2171040	2173920	that he gave on the Lotus Eaters podcast was not great
2173920	2176920	but also because he doesn't follow the drama, right?
2176920	2177760	Yeah.
2177760	2178600	He doesn't follow any of that drama.
2178600	2180160	And I'm like, dude, what the fuck are you doing?
2180160	2183520	He just used it to like virtue signal essentially,
2183520	2184360	in my opinion.
2187120	2190160	See, even though Sargon's my friend,
2190160	2193820	I still like disagree with a lot of the stuff
2193820	2196760	that they put out over in the Lotus Eaters.
2196760	2199280	I only really agree with it about half the time, you know?
2199280	2200680	Like a lot of times I'm like, no, Sargon.
2200680	2202560	But here's the thing, we're still friends, right?
2202560	2205680	Like I've had very, very spirited debates with him
2205680	2209000	in private over whatever, like many topics, right?
2209000	2210720	But we're still friends at the end of the day
2210720	2212560	because there's this understanding that like,
2212560	2214980	even though we're having this fight,
2214980	2217200	there's still the meta ethic of the friendship
2217200	2219480	that remains intact and you don't attack that.
2219480	2220680	You can have the debate,
2220680	2223120	but you don't attack the friendship, you know what I mean?
2227080	2228500	Yeah.
2228500	2232440	And it seems like a lot of people just don't do that.
2233160	2234000	They just don't.
2234000	2235960	They think that having a disagreement means
2235960	2237960	that you're not friends anymore.
2237960	2239320	It's like, what the fuck?
2239320	2240160	Yeah, I mean-
2240160	2243420	We're not 16 anymore, guys, like come on.
2243420	2244760	I don't necessarily think that,
2244760	2249760	but I think when somebody is like talking down to you
2250400	2253400	on a regular basis and like talking over you
2257400	2261360	and like mischaracterizing you in really public places,
2261360	2266000	I think that really does degrade a friendship, so.
2267400	2268560	Yeah, yeah, it does.
2268560	2271080	Especially if it's not like a joke, right?
2271080	2272560	Yeah.
2272560	2276600	Like I will publicly degrade Kibs every chance I get,
2276600	2278440	but we both know we're joking, you know?
2278440	2280320	Yeah, yeah.
2282360	2283880	That always sucks.
2283880	2284720	Yeah, that's okay then.
2284720	2288960	And you know what, like if the stuff with Mr. Girl
2288960	2292320	and then with Mind Waves has contributed in large part
2292320	2295680	to your recent malaise, I wouldn't be surprised
2295680	2299180	because to be honest, I took like, after my backstab,
2299180	2300020	I took like a month off.
2300020	2302080	I was like, I'm getting the fuck offline for a while.
2302080	2303640	Like, I'm just getting out of here, man.
2303640	2304800	I'm just piecing.
2304800	2307520	I'm doing some IRL stuff and I needed it to be honest.
2307520	2308640	I needed it.
2308640	2310280	Yeah, yeah.
2310280	2311900	Yeah, well, we'll see.
2311900	2315320	I mean, you know, there's multiple compounding factors
2315320	2320320	and stuff, but I think I had majority of my dip
2320640	2322040	like the past couple of months
2322040	2323420	and I think I'm coming out of it now.
2323420	2325440	So I'm really happy about that.
2325440	2326280	That's good.
2326280	2327120	That's good.
2327120	2327960	Yeah, coming out of it.
2327960	2329760	Everyone comes out of it eventually, you know?
2329760	2331800	Yeah, yeah, I think so.
2331800	2333360	Well, thank you for speaking with me.
2333360	2336000	Is there anything else that you wanted to talk about or?
2337320	2339520	Nothing I can think of off the top of my head.
2340640	2341480	Okay.
2341480	2344240	I've been here for like half an hour, 45 minutes.
2345200	2348920	Then watching me sell flag light as usual, so yeah.
2349880	2351760	That's long enough for me to turn into a clip
2351760	2354320	on my channel, ha ha ha ha ha.
2354320	2355160	Nice.
2356680	2359160	Listen, everyone who's watching this on my channel,
2359160	2360880	you know, in the next couple of days, whenever it goes out,
2360880	2363440	make sure to go sub to Stardust, okay?
2363440	2364400	Yeah, thank you.
2364400	2365840	Yeah.
2365840	2367020	Anyway, thanks for talking.
2367020	2367860	I'll see you later, okay?
2367860	2368680	Yeah, see you later.
2368680	2369520	Thanks for talking.
2369520	2371120	I really appreciate it.
2371120	2372000	Yeah, no problem.
2372000	2372840	Bye.
